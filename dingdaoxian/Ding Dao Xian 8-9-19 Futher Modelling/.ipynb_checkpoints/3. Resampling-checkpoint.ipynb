{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling methods are used to ensure that the model is good enough and can handle variations in data. The model does that by training it on the variety of patterns found in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Validation set approach </br><br>\n",
    "<font size=\"4\">\n",
    "<ul>\n",
    "    <li>The model is first created and put through a test and it is repeated until an optimal model</li>\n",
    "<li>Drawback 1 : What the model learns based on the training data is highly dependent on the observations including the training set. If there is an outlier observation, the model will tend to learn from outlier observations which may not be relevant in actual data.</li>\n",
    "    <li>Drawback 2 : Only a subset of observations is included in the training set. Excluding the observations for training means that the model will be deprived of learning the nuances of data in the test set. (Basically not enough info)</li>\n",
    "    </ul>\n",
    "In general, it will overestimate the test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"0.jpg\" align=\"center\" height = \"20\" width = \"800\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. K-Fold Cross-Validation <br></br>\n",
    "<font size=\"4\">\n",
    "<ul>\n",
    "    <li> K-fold cross-validation method is used to overcome these challenges.</li>\n",
    "    <li> Steps : </li>\n",
    "    <ol>\n",
    "        <li>The data is split into something called fold (k). Typically, there are 5 or 10 equal folds. Each fold has a random set of data points.</li>\n",
    "        <li>In the first iteration, the model is trained on (k-1) folds and tested on the one left out fold.</li>\n",
    "        <li>This process is repeated until the model is trained and tested on all the folds.</li>\n",
    "    </ol>\n",
    "    <li>The overall performance of the model is computed based on mean error across all the iterations.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"0 (1).jpg\" align=\"center\" height = \"10\" width = \"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Calculating overall performance of the model <br></br>\n",
    "<img src=\"mse.png\" align=\"left\"/><img src=\"err.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "LHS :The mean error across all the folds for a regression model(MSE is Mean Square ERROR)<br></br>\n",
    "RHS :The mean error across all the folds for a classifier where Err can be classifier metrics like AUC, Recall, Precision etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "<ul>\n",
    "    <li>It mainly does an excellent job of reducing bias. It does it elegantly by training and testing on each of the folds.</li>\n",
    "    <li>time-consuming as compared to a simplistic approach taken by the validation set approach. The time consumed is evident as the cross-validation method trains (k-1) times more than the validation set approach. This issue can be more pronounced, especially if the training set is large.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bootstrap Sampling  <br></br>\n",
    "<font size=\"4\">\n",
    "<ul>\n",
    "    <li> Quantify the uncertainty associated with an estimator. </li>\n",
    "    <li> Steps : </li>\n",
    "    <ol>\n",
    "        <li>Collect distinct data sets by repeatedly sampling observations from the original data set with replacement.</li>\n",
    "        <li>Each of the bootstrap data sets is created by sampling with replacement and is the same size the original data set.</li>\n",
    "        <li>An observation may appear more than once in a bootstrap sample or not at all.</li>\n",
    "    </ol>\n",
    "    <li>Bassically, rather than keep training the model, it switches aroudn the data</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "    <img src=\"bootstrap.jpg\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol><li>The original dataset has ten observations.</li><li>The training set is the <em>same size</em> as the original dataset, i.e., training is done on ten observations. However, observations in the training sets are repeated from the original dataset. In the example above, for the first iterations, observations 2, 3, 4, and 9 are repeated from the original dataset. Observation #1 is not repeated.</li><li>Once the model is trained, it is tested on the unseen data. Unseen data are those observations that are not in training data set but are present in the original dataset. The test data set is the <em>original dataset â€” training dataset.</em></li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "<ul>\n",
    "    <li>This process continues for a prescribed number of bootstrap samples (typically in the range of 1000 samples)</li>\n",
    "    <li>The overall bootstrap estimate is the average of the estimates obtained from each bootstrap sample estimate.</li>\n",
    "    <li>Bootstrap estimate will have lower variance in its estimation as compared to a general train-test split mechanism.</li>\n",
    "    <li>If there are a relatively fewer observation of interests, bootstrap sampling can be used to repeatedly sampling the same observation in the dataset for training.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Conclusion/Standard practise <br></br>\n",
    "<font size =\"4\">\n",
    "<ol>\n",
    "    <li>If sample data is small or has lots of outliers, then it goes through Bootstrap Sampling</li>\n",
    "    <li>Otherwise the simple validation method is used for the quick creation of the model </li>\n",
    "    <li>It is then further enhanced by using K-fold cross-validation method.</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
